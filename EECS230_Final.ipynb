{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2837339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    function code_toggle() {\n",
       "        if ($('div.cell.code_cell.rendered.selected div.input').css('display')!='none'){\n",
       "            $('div.cell.code_cell.rendered.selected div.input').hide();\n",
       "        } else {\n",
       "            $('div.cell.code_cell.rendered.selected div.input').show();\n",
       "        }\n",
       "    }\n",
       "    </script>\n",
       "\n",
       "\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Hide/Unhide\"></form>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from hide_cell import toggle_code as hide_cell\n",
    "# Pip install necessary package\n",
    "!pip install -U --quiet  huggingface_hub\n",
    "%pip install --upgrade --quiet  pgvector\n",
    "%pip install --upgrade --quiet  langchain-openai\n",
    "%pip install --upgrade --quiet  psycopg2-binary\n",
    "%pip install --upgrade --quiet  tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0a476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765d39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, numpy as np, pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1a2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\") or os.getenv(\"HF_TOKEN\") or os.getenv(\"HF_API_KEY\")\n",
    "if not token:\n",
    "    raise RuntimeError(\"Set HUGGINGFACEHUB_API_TOKEN or HF_TOKEN before running.\")\n",
    "login(token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ff7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded...\n",
      "<class 'numpy.ndarray'>\n",
      "['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'\n",
      " 'What is in front of the Notre Dame Main Building?'\n",
      " 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?'\n",
      " ... 'With what Belorussian city does Kathmandu have a relationship?'\n",
      " 'In what year did Kathmandu create its initial international relationship?'\n",
      " 'What is KMC an initialism of?']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "print(\"Dataset loaded...\")\n",
    "\n",
    "answers_train, answers_valid = np.array([]), np.array([])\n",
    "\n",
    "questions_train = np.array(dataset[\"train\"][\"question\"])\n",
    "questions_valid = np.array(dataset[\"validation\"][\"question\"])\n",
    "\n",
    "print(type(questions_train))\n",
    "print(questions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b6ca331",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#x = pd.DataFrame(dataset[\"train\"][\"answers\"])[\"text\"]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mx\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#x = pd.DataFrame(dataset[\"train\"][\"answers\"])[\"text\"]\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b478cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_train = pd.DataFrame(dataset[\"train\"][\"answers\"])[\"text\"]\n",
    "answers_valid = pd.DataFrame(dataset[\"validation\"][\"answers\"])[\"text\"]\n",
    "answers_train = np.array(answers_train)\n",
    "answers_valid = np.array(answers_valid)\n",
    "\n",
    "#print(\"Saving files...\")\n",
    "\n",
    "#np.save(\"data/questions_train.npy\", questions_train)\n",
    "#np.save(\"data/questions_valid.npy\", questions_valid)\n",
    "#np.save(\"data/answers_train.npy\", answers_train)\n",
    "#np.save(\"data/answers_valid.npy\", answers_valid)\n",
    "\n",
    "#print(len(answers), type(answers), answers[30])\n",
    "#print(len(questions), type(questions), questions[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7a4dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Denver Broncos', 'Denver Broncos', 'Denver Broncos']),\n",
       "       list(['Carolina Panthers', 'Carolina Panthers', 'Carolina Panthers']),\n",
       "       list(['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"]),\n",
       "       list(['Denver Broncos', 'Denver Broncos', 'Denver Broncos']),\n",
       "       list(['gold', 'gold', 'gold']),\n",
       "       list(['\"golden anniversary\"', 'gold-themed', '\"golden anniversary']),\n",
       "       list(['February 7, 2016', 'February 7', 'February 7, 2016']),\n",
       "       list(['American Football Conference', 'American Football Conference', 'American Football Conference']),\n",
       "       list(['\"golden anniversary\"', 'gold-themed', 'gold']),\n",
       "       list(['American Football Conference', 'American Football Conference', 'American Football Conference'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train[:10]\n",
    "answers_valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea9eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = np.array(dataset[\"train\"][\"title\"])\n",
    "articles = np.array(dataset[\"train\"][\"context\"])\n",
    "articles = pd.DataFrame(data=[titles, articles]).T.drop_duplicates()\n",
    "articles.columns = [\"Titles\", \"Content\"]\n",
    "articles = articles.reset_index(drop=True)\n",
    "#articles.to_csv(\"articles.csv\", sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081bb2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14153, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>All of Notre Dame's undergraduate students are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Titles                                            Content\n",
       "0  University_of_Notre_Dame  Architecturally, the school has a Catholic cha...\n",
       "1  University_of_Notre_Dame  As at most other universities, Notre Dame's st...\n",
       "2  University_of_Notre_Dame  The university is the major seat of the Congre...\n",
       "3  University_of_Notre_Dame  The College of Engineering was established in ...\n",
       "4  University_of_Notre_Dame  All of Notre Dame's undergraduate students are..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv(\"articles.csv\", sep='|', )\n",
    "print(articles.shape)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac0913c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 3706\n"
     ]
    }
   ],
   "source": [
    "content = articles[\"Content\"].apply(len)\n",
    "print(content.min(), content.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(articles[\"Content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4531d883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started tokenizing...\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-small-en-v1.5')\n",
    "model = AutoModel.from_pretrained('BAAI/bge-small-en-v1.5')\n",
    "model.eval()\n",
    "\n",
    "print(\"Started tokenizing...\")\n",
    "all_sentence_embeddings = torch.randn(0)\n",
    "\n",
    "# Tokenize sentences\n",
    "for i in range(187, articles.shape[0] // 100 + 1):\n",
    "    #print(i)\n",
    "    encoded_input = tokenizer(sentences[i*100:min(i*100+100, articles.shape[0])], padding=True, truncation=True, return_tensors='pt')\n",
    "    # for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "    # encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    # normalize embeddings\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    all_sentence_embeddings = torch.cat((all_sentence_embeddings, sentence_embeddings), dim=0)\n",
    "    \n",
    "    if i % 10 == 0: print(\"... +1000 embeddings done\")\n",
    "    #print(\"Sentence embeddings:\", sentence_embeddings)\n",
    "    #print(type(sentence_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f7ab706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([282, 384])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_embeddings.size()\n",
    "#articles.shape[0] // 100 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8f14aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9940e-03,  1.0652e-01,  5.3358e-03,  5.3919e-02,  7.5591e-03,\n",
       "        -4.0923e-02,  4.7185e-03, -3.0655e-02, -4.4956e-02,  1.1459e-02,\n",
       "         3.8129e-02, -6.8489e-02,  2.5115e-02,  1.0912e-02, -1.6136e-02,\n",
       "         4.8968e-02, -7.3896e-02, -2.3109e-02,  5.1400e-02, -1.3878e-02,\n",
       "        -6.2728e-02, -1.7276e-02,  3.0784e-02, -3.7519e-03,  5.1968e-03,\n",
       "         2.5703e-02, -1.7471e-02, -3.0858e-02, -4.6582e-03, -1.2557e-01,\n",
       "        -2.9843e-02,  6.9997e-03, -1.9401e-02, -1.5090e-02, -4.3128e-02,\n",
       "         2.7862e-02,  2.4029e-02,  2.4787e-04, -8.1142e-03,  6.7506e-02,\n",
       "        -3.4796e-02,  5.2754e-02,  5.0778e-02, -1.2876e-02, -6.5529e-02,\n",
       "         4.7585e-02, -2.1723e-03, -4.2348e-03, -2.5838e-02, -3.0642e-02,\n",
       "        -2.0854e-02, -3.3128e-02, -3.7983e-02,  4.0164e-02, -5.4660e-03,\n",
       "        -2.6455e-02,  6.3354e-02,  7.9515e-04,  2.3316e-02, -9.2074e-02,\n",
       "         5.8536e-02, -1.0653e-02, -1.4199e-01,  2.7099e-02,  1.1381e-02,\n",
       "         4.1571e-02,  1.6465e-03, -3.6719e-02, -7.0044e-03, -8.8412e-02,\n",
       "        -3.2998e-02,  6.8687e-02,  1.7605e-02,  4.8007e-03,  1.8684e-02,\n",
       "         3.6807e-03,  4.3360e-02,  1.3202e-02, -7.2646e-02,  2.9055e-02,\n",
       "        -7.1667e-03,  3.2546e-02, -7.0892e-03, -2.9075e-02,  3.2754e-03,\n",
       "         3.6981e-02,  3.2353e-02, -3.4100e-02,  7.5861e-03,  1.9837e-02,\n",
       "        -5.4840e-04,  2.3866e-02,  4.4524e-02,  5.7933e-02, -4.9362e-02,\n",
       "         9.9628e-03,  2.1378e-02,  8.3066e-02,  1.8546e-02,  3.6286e-01,\n",
       "        -6.1052e-02,  6.1990e-02,  2.0987e-02,  4.2772e-02, -2.9740e-03,\n",
       "         1.0808e-02, -4.0296e-02,  8.4033e-03, -1.2348e-02,  6.5984e-02,\n",
       "         1.2124e-02,  3.7193e-02,  1.4873e-02,  5.8847e-02,  2.1086e-02,\n",
       "        -5.8207e-02,  7.8984e-03,  5.2016e-02,  1.8733e-02,  6.2912e-02,\n",
       "        -5.0682e-02, -2.3400e-02,  1.2129e-01, -1.5568e-02,  4.4100e-02,\n",
       "         1.2732e-02,  6.8156e-03,  8.3601e-02,  7.5606e-02, -2.7917e-02,\n",
       "         1.6794e-02, -4.5691e-02, -3.1860e-02, -4.8924e-02, -3.1368e-02,\n",
       "        -5.1439e-03, -8.1573e-03, -2.0504e-03, -1.1739e-02, -5.1294e-02,\n",
       "        -1.0499e-02, -5.9723e-02,  1.7007e-02, -3.4623e-02, -7.1705e-03,\n",
       "        -3.1029e-02,  5.1382e-02,  8.5056e-03, -4.0267e-02,  4.3180e-02,\n",
       "        -3.2639e-02,  2.9990e-02, -3.4530e-02,  2.7843e-02,  2.4157e-02,\n",
       "         1.5906e-02,  5.8775e-02,  2.1747e-02, -2.4241e-02, -1.0117e-01,\n",
       "        -1.0245e-03, -4.2561e-02, -1.1443e-02,  3.8154e-02,  6.5108e-02,\n",
       "        -9.4376e-02, -2.2632e-02,  3.2057e-02,  3.3770e-02,  6.9982e-03,\n",
       "         4.6713e-02, -6.5635e-03, -1.3141e-02, -1.8160e-02,  7.9084e-02,\n",
       "         3.8494e-02, -7.3613e-02,  6.3243e-02, -5.1609e-02, -2.3089e-02,\n",
       "         4.6305e-02, -9.9542e-03, -2.4508e-02,  2.5033e-03, -3.3280e-02,\n",
       "        -4.1543e-02, -5.4452e-02, -1.2035e-02,  8.5111e-02, -8.6333e-03,\n",
       "         2.3116e-02, -5.1711e-02, -5.1428e-03, -2.2634e-02,  6.1827e-02,\n",
       "         2.6970e-02,  3.8404e-02, -6.7800e-03,  3.7684e-02,  3.1638e-03,\n",
       "        -8.4732e-02,  4.0780e-02,  7.0775e-03, -5.5659e-02,  6.2868e-02,\n",
       "         4.9378e-03,  7.1611e-02, -4.6234e-02,  4.0724e-02, -1.5798e-02,\n",
       "        -2.1415e-02,  4.8840e-03,  7.7610e-03,  3.0309e-02,  1.5348e-02,\n",
       "        -6.3285e-03,  6.4596e-02, -8.0116e-02, -3.5267e-02,  1.1236e-02,\n",
       "         1.6766e-02, -1.0651e-01, -1.8600e-03, -2.8156e-01, -4.5161e-02,\n",
       "        -1.2514e-02, -1.8657e-02,  3.6451e-02, -1.6331e-02, -3.5403e-02,\n",
       "         2.6086e-02,  2.4568e-02,  4.6161e-02, -3.9234e-02,  3.6459e-02,\n",
       "         1.0661e-02,  7.8410e-02,  2.2181e-02,  7.6245e-02, -3.1626e-02,\n",
       "        -5.6732e-02, -2.8730e-02, -2.1177e-02, -2.2978e-02, -8.6026e-03,\n",
       "        -4.6677e-02, -5.1329e-02,  4.3330e-02, -2.8208e-02,  1.7292e-01,\n",
       "         2.6422e-02, -1.0163e-01, -6.4536e-02, -4.4358e-02,  3.3102e-02,\n",
       "        -3.5763e-02, -4.5442e-02, -8.3393e-03, -6.8606e-03,  1.2823e-02,\n",
       "        -7.9775e-02,  5.6714e-02, -2.3331e-02,  3.1410e-02,  2.1982e-02,\n",
       "        -7.3551e-03,  1.1131e-02, -4.3132e-02, -1.0751e-02, -5.4424e-02,\n",
       "        -6.4344e-03,  2.9714e-02, -3.9831e-02,  2.5394e-02,  5.2739e-02,\n",
       "        -1.6505e-02,  2.9245e-02, -1.4036e-01, -2.7209e-02, -8.1230e-02,\n",
       "        -1.7694e-03, -1.1122e-02,  5.5051e-02, -3.1073e-03, -9.7318e-03,\n",
       "        -2.9052e-02, -7.7115e-03,  4.7155e-02,  2.4281e-02, -2.1874e-02,\n",
       "         3.4316e-02,  2.0483e-02, -5.9391e-02, -3.1166e-02,  6.6043e-02,\n",
       "        -8.9266e-02, -1.0491e-01, -1.6372e-04, -2.3334e-02,  2.4594e-02,\n",
       "        -3.1009e-02,  9.5087e-03,  6.4212e-02,  5.9125e-02, -2.4278e-02,\n",
       "         3.9684e-02,  6.3559e-02,  6.1543e-02,  7.0488e-02,  1.8414e-02,\n",
       "        -3.4349e-03,  1.0262e-02, -9.8075e-04,  4.5030e-02, -9.4422e-04,\n",
       "        -4.5853e-02, -1.7246e-02, -3.6134e-02,  4.6984e-02, -1.9826e-01,\n",
       "         3.0883e-02,  4.8987e-02, -2.2628e-02,  3.0693e-02, -6.1703e-03,\n",
       "         2.2780e-02,  3.9818e-02, -8.3800e-03,  4.3909e-02,  8.4651e-02,\n",
       "         6.6896e-02,  5.9664e-02,  6.1999e-02,  4.9722e-02, -2.7340e-02,\n",
       "         2.3562e-02, -3.2609e-02,  1.2512e-02, -1.1513e-01,  9.6675e-03,\n",
       "        -2.2908e-02,  1.4015e-01,  7.8212e-02, -2.2281e-02,  1.1536e-02,\n",
       "         2.7767e-02, -3.9985e-03, -6.3361e-02, -6.9804e-03,  9.9894e-03,\n",
       "        -3.1804e-02,  1.2596e-01, -3.9068e-02, -3.9050e-03,  3.9775e-02,\n",
       "         8.8149e-03, -3.6587e-02,  1.2320e-02, -1.3913e-02, -4.4197e-02,\n",
       "        -6.7920e-03, -2.7711e-02, -3.2338e-03,  7.0459e-02, -4.9244e-02,\n",
       "        -4.6135e-02, -8.5289e-02,  3.6798e-02, -2.4392e-02, -2.6054e-02,\n",
       "        -6.9208e-02, -9.1019e-05, -2.4918e-02, -1.8161e-03, -5.3098e-03,\n",
       "        -1.8756e-02, -5.7717e-03, -3.0610e-03, -1.5870e-02, -7.1638e-03,\n",
       "         4.0029e-02, -6.6795e-02, -3.9133e-02,  1.3093e-02])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_embeddings[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63fe2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7611,  0.5862],\n",
       "        [-0.0470, -0.5591],\n",
       "        [-0.3606, -0.7509],\n",
       "        [-0.7611,  0.5862],\n",
       "        [-0.0470, -0.5591],\n",
       "        [-0.3606, -0.7509]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_embeddings = torch.randn(0)\n",
    "all_sentence_embeddings\n",
    "sentence_embeddings = torch.randn(3,2)\n",
    "all_sentence_embeddings = torch.cat((all_sentence_embeddings, sentence_embeddings), dim=0)\n",
    "all_sentence_embeddings = torch.cat((all_sentence_embeddings, sentence_embeddings), dim=0)\n",
    "all_sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((all_sentence_embeddings, sentence_embeddings), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "978415c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What do greenhouses do with solar energy?'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"question\"][4999:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b7b65b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2008_Sichuan_earthquake', 'Antibiotics', 'Beyoncé',\n",
       "       'Frédéric_Chopin', 'Genocide', 'IPod', 'Montana', 'New_York_City',\n",
       "       'Sino-Tibetan_relations_during_the_Ming_dynasty', 'Solar_energy',\n",
       "       'Spectre_(2015_film)', 'The_Legend_of_Zelda:_Twilight_Princess',\n",
       "       'To_Kill_a_Mockingbird', 'University_of_Notre_Dame'], dtype='<U46')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(dataset[\"train\"][\"title\"][:5102]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c941407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1973_oil_crisis', 'Amazon_rainforest',\n",
       "       'American_Broadcasting_Company', 'Apollo_program', 'Black_Death',\n",
       "       'Chloroplast', 'Civil_disobedience',\n",
       "       'Computational_complexity_theory', 'Construction', 'Ctenophora',\n",
       "       'Doctor_Who', 'Economic_inequality', 'European_Union_law', 'Force',\n",
       "       'French_and_Indian_War', 'Fresno,_California', 'Genghis_Khan',\n",
       "       'Geology', 'Harvard_University', 'Huguenot', 'Immune_system',\n",
       "       'Imperialism', 'Intergovernmental_Panel_on_Climate_Change',\n",
       "       'Islamism', 'Jacksonville,_Florida', 'Kenya', 'Martin_Luther',\n",
       "       'Newcastle_upon_Tyne', 'Nikola_Tesla', 'Normans', 'Oxygen',\n",
       "       'Packet_switching', 'Pharmacy', 'Prime_number', 'Private_school',\n",
       "       'Rhine', 'Scottish_Parliament', 'Sky_(United_Kingdom)',\n",
       "       'Southern_California', 'Steam_engine', 'Super_Bowl_50', 'Teacher',\n",
       "       'United_Methodist_Church', 'University_of_Chicago',\n",
       "       'Victoria_(Australia)', 'Victoria_and_Albert_Museum', 'Warsaw',\n",
       "       'Yuan_dynasty'], dtype='<U41')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(dataset[\"validation\"][\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f9c0209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(dataset[\"validation\"][\"context\"]))\n",
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "27154cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_qna = len(np.array(dataset[\"validation\"][\"context\"]))\n",
    "np.random.seed(90)\n",
    "test_idx = np.random.choice(num_of_qna, size=num_of_qna//5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "19a5308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_test = questions_valid[test_idx]\n",
    "answers_test = answers_valid[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c475e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.setdiff1d(np.arange(num_of_qna), test_idx)\n",
    "questions_train = questions_valid[train_idx]\n",
    "answers_train = answers_valid[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7d2ae81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5270b2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2114"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1b9ba103",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/questions_train.npy\", questions_train)\n",
    "np.save(\"data/questions_test.npy\", questions_test)\n",
    "np.save(\"data/answers_train.npy\", answers_train)\n",
    "np.save(\"data/answers_test.npy\", answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "70707822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d6d9b6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__main__.<lambda>() got multiple values for keyword argument 'allow_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/answers_test.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m a_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/answers_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m q_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/questions_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[165], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*a, **k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: np_load_old(\u001b[38;5;241m*\u001b[39ma, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "\u001b[1;31mTypeError\u001b[0m: __main__.<lambda>() got multiple values for keyword argument 'allow_pickle'"
     ]
    }
   ],
   "source": [
    "a_test = np.load(\"data/answers_test.npy\", allow_pickle=True)\n",
    "a_train = np.load(\"data/answers_train.npy\", allow_pickle=True)\n",
    "q_test = np.load(\"data/questions_test.npy\", allow_pickle=True)\n",
    "q_train = np.load(\"data/questions_train.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "74e22026",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = np.array(dataset[\"validation\"][\"title\"])\n",
    "articles = np.array(dataset[\"validation\"][\"context\"])\n",
    "articles = pd.DataFrame(data=[titles, articles]).T.drop_duplicates()\n",
    "articles.columns = [\"Titles\", \"Content\"]\n",
    "articles = articles.reset_index(drop=True)\n",
    "articles.to_csv(\"data/articles.csv\", sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda013f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
